{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QP6Y_O3zB6u4"
   },
   "source": [
    "# Notebook information\n",
    "Dataset corresponds to these three categories: \n",
    "-> Healthy\n",
    "-> Bacterial-pneumonia\n",
    "-> Viral-pneumonia\n",
    "\n",
    "If chest x-rays is Bacterial-pneumonia + Viral-pneumonia, this person is infected with covid-19. Reason for not grouping Bacterial-pneumonia and Viral-pneumonia into one category is because there is different features in the images to look out for in these two categories. Combining them will mess things up as accuracy would be affected, there could be misclassification. Another pointer, is that there is uneven quantity of data in these respective categories. To illustrate, we have 2000+ imgs of Bacterail-pneumonia but only 1400 imgs of healthy lungs. Hence, acc will def be affected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:10:42.898599Z",
     "iopub.status.busy": "2021-10-23T10:10:42.898250Z",
     "iopub.status.idle": "2021-10-23T10:10:47.399313Z",
     "shell.execute_reply": "2021-10-23T10:10:47.398404Z",
     "shell.execute_reply.started": "2021-10-23T10:10:42.898524Z"
    },
    "id": "vRCm9x4BB6u5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpLNtlCsB6u7"
   },
   "source": [
    "# Reading in and looking @ data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:10:47.401049Z",
     "iopub.status.busy": "2021-10-23T10:10:47.400697Z",
     "iopub.status.idle": "2021-10-23T10:10:47.453603Z",
     "shell.execute_reply": "2021-10-23T10:10:47.452803Z",
     "shell.execute_reply.started": "2021-10-23T10:10:47.401013Z"
    },
    "id": "_APB0BMjGOfv",
    "outputId": "bac16d58-8710-4937-eaf1-5a2e3c524a61"
   },
   "outputs": [],
   "source": [
    "metadata=pd.read_csv(\"../input/coronahack-chest-xraydataset/Chest_xray_Corona_Metadata.csv\")\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:10:47.455896Z",
     "iopub.status.busy": "2021-10-23T10:10:47.455530Z",
     "iopub.status.idle": "2021-10-23T10:10:47.738327Z",
     "shell.execute_reply": "2021-10-23T10:10:47.737446Z",
     "shell.execute_reply.started": "2021-10-23T10:10:47.455860Z"
    },
    "id": "UNRpd3pEGP3b",
    "outputId": "03ac29e9-7cf9-4b36-d62d-f7d5707c022f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2,figsize=(20, 5))\n",
    "ax[0].hist(metadata['Label']);\n",
    "ax[1].hist(metadata['Label_1_Virus_category'].astype(str));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K6JM9QHZB6u9"
   },
   "source": [
    "# Divide the data to three categories(test, valid, training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:10:47.740503Z",
     "iopub.status.busy": "2021-10-23T10:10:47.740147Z",
     "iopub.status.idle": "2021-10-23T10:10:47.750002Z",
     "shell.execute_reply": "2021-10-23T10:10:47.748460Z",
     "shell.execute_reply.started": "2021-10-23T10:10:47.740467Z"
    },
    "id": "QSK3AewsGUCX"
   },
   "outputs": [],
   "source": [
    "#get training data and testing data\n",
    "train_df = metadata[metadata['Dataset_type'] == 'TRAIN']\n",
    "test_df = metadata[metadata['Dataset_type'] == 'TEST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:10:47.752195Z",
     "iopub.status.busy": "2021-10-23T10:10:47.751718Z",
     "iopub.status.idle": "2021-10-23T10:10:47.767999Z",
     "shell.execute_reply": "2021-10-23T10:10:47.767304Z",
     "shell.execute_reply.started": "2021-10-23T10:10:47.752140Z"
    },
    "id": "LxCwRByfGWdQ",
    "outputId": "1578751a-8cfe-4fbb-82b9-c54e2245b46a"
   },
   "outputs": [],
   "source": [
    "#Divide each virus with corresponding images to different variables\n",
    "train_virus = train_df[train_df.Label_1_Virus_category == 'Virus']['X_ray_image_name']\n",
    "train_bacterial=train_df[train_df.Label_1_Virus_category == 'bacteria']['X_ray_image_name']\n",
    "train_normal=train_df[train_df.Label == 'Normal']['X_ray_image_name']\n",
    "\n",
    "len(train_virus),len(train_bacterial),len(train_normal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the data to test,valid and training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:10:47.769609Z",
     "iopub.status.busy": "2021-10-23T10:10:47.769282Z",
     "iopub.status.idle": "2021-10-23T10:10:47.775760Z",
     "shell.execute_reply": "2021-10-23T10:10:47.774570Z",
     "shell.execute_reply.started": "2021-10-23T10:10:47.769576Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_to_training_validation(data,split=0.2):\n",
    "    \"\"\"\n",
    "    20% -> validation\n",
    "    80% -> training\n",
    "    \n",
    "    data -> data series images \n",
    "    split -> pararmeter to split\n",
    "    \n",
    "    returns a validation and training set\n",
    "    \"\"\"\n",
    "    \n",
    "    valid_data=data[:round(split*len(data))]\n",
    "    train_data=data[round(split*len(data)):]\n",
    "    \n",
    "    return valid_data, train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:10:47.778247Z",
     "iopub.status.busy": "2021-10-23T10:10:47.777540Z",
     "iopub.status.idle": "2021-10-23T10:10:47.788485Z",
     "shell.execute_reply": "2021-10-23T10:10:47.786951Z",
     "shell.execute_reply.started": "2021-10-23T10:10:47.778211Z"
    }
   },
   "outputs": [],
   "source": [
    "valid_virus,train_virus=split_to_training_validation(train_virus)\n",
    "valid_bacterial,train_bacterial=split_to_training_validation(train_bacterial)\n",
    "valid_normal,train_normal=split_to_training_validation(train_normal)\n",
    "\n",
    "len(train_virus),len(valid_virus), len(valid_normal),len(train_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:10:47.792310Z",
     "iopub.status.busy": "2021-10-23T10:10:47.791857Z",
     "iopub.status.idle": "2021-10-23T10:11:24.331706Z",
     "shell.execute_reply": "2021-10-23T10:11:24.330881Z",
     "shell.execute_reply.started": "2021-10-23T10:10:47.792252Z"
    }
   },
   "outputs": [],
   "source": [
    "lables=['Healthy','Viral-pneumonia','Bacterial-pneumonia']\n",
    "training_data_classes=[train_normal,train_virus,train_bacterial]\n",
    "source='../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/train'\n",
    "\n",
    "for i in range(0,len(lables)):\n",
    "    target='/dataset/train/'+lables[i] #choose where the data from kaggle should be placed\n",
    "    \n",
    "    \n",
    "    \n",
    "    os.makedirs('/dataset/train/'+lables[i]) #create new folder with lables\n",
    "    move=training_data_classes[i]\n",
    "    for j in move:\n",
    "        \n",
    "        \n",
    "        #move everything from source path to new target path as iterating through the labels\n",
    "        path=os.path.join(source,j)\n",
    "        shutil.copy(path,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:24.335654Z",
     "iopub.status.busy": "2021-10-23T10:11:24.335385Z",
     "iopub.status.idle": "2021-10-23T10:11:33.470408Z",
     "shell.execute_reply": "2021-10-23T10:11:33.469517Z",
     "shell.execute_reply.started": "2021-10-23T10:11:24.335629Z"
    }
   },
   "outputs": [],
   "source": [
    "validation_data_classes=[valid_normal,valid_virus,valid_bacterial]\n",
    "for i in range(0,len(lables)):\n",
    "    target='/dataset/valid/'+lables[i] #choose where the data from kaggle should be placed\n",
    "    \n",
    "    \n",
    "    \n",
    "    os.makedirs('/dataset/valid/'+lables[i]) #create new folder with lables\n",
    "    move=validation_data_classes[i]\n",
    "    for j in move:\n",
    "        #move everything from source path to new target path as iterating through the labels\n",
    "        path=os.path.join(source,j)\n",
    "        shutil.copy(path,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:33.474032Z",
     "iopub.status.busy": "2021-10-23T10:11:33.473738Z",
     "iopub.status.idle": "2021-10-23T10:11:33.486927Z",
     "shell.execute_reply": "2021-10-23T10:11:33.486155Z",
     "shell.execute_reply.started": "2021-10-23T10:11:33.474003Z"
    },
    "id": "4OClqZBLGaoM"
   },
   "outputs": [],
   "source": [
    "test_virus = test_df[test_df.Label_1_Virus_category == 'Virus']['X_ray_image_name']\n",
    "test_bacterial=test_df[test_df.Label_1_Virus_category == 'bacteria']['X_ray_image_name']\n",
    "test_normal=test_df[test_df.Label == 'Normal']['X_ray_image_name']\n",
    "\n",
    "len(test_virus),len(test_bacterial),len(test_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:33.488722Z",
     "iopub.status.busy": "2021-10-23T10:11:33.488343Z",
     "iopub.status.idle": "2021-10-23T10:11:38.538654Z",
     "shell.execute_reply": "2021-10-23T10:11:38.537803Z",
     "shell.execute_reply.started": "2021-10-23T10:11:33.488685Z"
    },
    "id": "rDegpHtOGesh"
   },
   "outputs": [],
   "source": [
    "classes=[test_normal,test_virus,test_bacterial]\n",
    "source='../input/coronahack-chest-xraydataset/Coronahack-Chest-XRay-Dataset/Coronahack-Chest-XRay-Dataset/test'\n",
    "\n",
    "for i in range(0,len(lables)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    target='/dataset/test/'+lables[i] #choose where the data from kaggle should be placed \n",
    "    \n",
    "    \n",
    "    \n",
    "    os.makedirs('/dataset/test/'+lables[i]) #create new folder with lables\n",
    "    move=classes[i]\n",
    "    for j in move:\n",
    "        #move everything from source path to new target path as iterating through the labels\n",
    "        path=os.path.join(source,j)\n",
    "        shutil.copy(path,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sh_2brQ-B6u_"
   },
   "source": [
    "**Get class names to confirm the division is done right**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:38.541163Z",
     "iopub.status.busy": "2021-10-23T10:11:38.540911Z",
     "iopub.status.idle": "2021-10-23T10:11:38.549450Z",
     "shell.execute_reply": "2021-10-23T10:11:38.548532Z",
     "shell.execute_reply.started": "2021-10-23T10:11:38.541139Z"
    },
    "id": "aoDKyIPOXT96",
    "outputId": "edb86c20-efb0-40bf-fc3a-e122e63eeb76"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "\n",
    "\n",
    "#Print out classes from the created directory\n",
    "data_dir = pathlib.Path(\"/dataset/valid\")\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob(\"*\")])) # Created a list of class_names from the subdirectories\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CoRBZaAkB6vA"
   },
   "source": [
    "**Plot one random image of bacterial-pneumonia lung (it can be changed to others by changing the target_class arg)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:38.551205Z",
     "iopub.status.busy": "2021-10-23T10:11:38.550667Z",
     "iopub.status.idle": "2021-10-23T10:11:38.810854Z",
     "shell.execute_reply": "2021-10-23T10:11:38.809749Z",
     "shell.execute_reply.started": "2021-10-23T10:11:38.551170Z"
    },
    "id": "cH0EYobvXxy7"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from matplotlib.pyplot import figure\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "def view_random_image(target_dir, target_class):\n",
    "    # Setup the target directory \n",
    "    target_folder = target_dir+target_class\n",
    "\n",
    "    # Get a random image path\n",
    "    random_image = random.sample(os.listdir(target_folder), 1)\n",
    "    print(random_image)\n",
    "    \n",
    "    # Read in the image and plot it using matplotlib\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.subplot(1, 1,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    img = mpimg.imread(target_folder + \"/\" + random_image[0])\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.title(target_class)\n",
    "    plt.axis(\"off\");\n",
    "    print(f\"Image shape: {img.shape}\") # show the shape of the image\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:38.812821Z",
     "iopub.status.busy": "2021-10-23T10:11:38.812445Z",
     "iopub.status.idle": "2021-10-23T10:11:39.057506Z",
     "shell.execute_reply": "2021-10-23T10:11:39.056606Z",
     "shell.execute_reply.started": "2021-10-23T10:11:38.812774Z"
    },
    "id": "nb_PtJTbXzXb",
    "outputId": "90fd0d0a-ed28-40ac-a56d-07aace921782"
   },
   "outputs": [],
   "source": [
    "#dir and class can be changed\n",
    "image_1= view_random_image(target_dir=\"/dataset/valid/\",\n",
    "                        target_class=\"Bacterial-pneumonia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jaAX2VtVB6vA"
   },
   "source": [
    "# Preprocessing data for the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validation is used when fitting the model\n",
    "* This ensures that hyperparameter tuning isnt chosen based on the unseen test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:39.058927Z",
     "iopub.status.busy": "2021-10-23T10:11:39.058599Z",
     "iopub.status.idle": "2021-10-23T10:11:39.384388Z",
     "shell.execute_reply": "2021-10-23T10:11:39.383636Z",
     "shell.execute_reply.started": "2021-10-23T10:11:39.058892Z"
    },
    "id": "_yoBDaGtYMGN",
    "outputId": "d0edd999-ee1b-492d-9d62-5ad1f66d6540"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "#Define training and testing directories\n",
    "train_dir = \"/dataset/train\"\n",
    "valid_dir=\"/dataset/valid\"\n",
    "test_dir = \"/dataset/test\"\n",
    "\n",
    "#Normalize images\n",
    "train_aug = ImageDataGenerator(rescale=1/255.,\n",
    "                               shear_range=0.1,\n",
    "                               rotation_range=20,\n",
    "                               zoom_range=0.1)\n",
    "\n",
    "valid_gen=ImageDataGenerator(rescale=1/255.)\n",
    "test_gen = ImageDataGenerator(rescale=1/255.)\n",
    "\n",
    "\n",
    "train_data = train_aug.flow_from_directory(train_dir,\n",
    "                                          target_size=IMG_SIZE,\n",
    "                                          color_mode='grayscale',\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          class_mode=\"categorical\")\n",
    "\n",
    "valid_data=valid_gen.flow_from_directory(valid_dir,\n",
    "                                        target_size=IMG_SIZE,\n",
    "                                        color_mode='grayscale',\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        class_mode=\"categorical\")\n",
    "\n",
    "test_data = test_gen.flow_from_directory(test_dir,\n",
    "                                        target_size=IMG_SIZE,\n",
    "                                        color_mode='grayscale',\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **4228** images for training\n",
    "* **1056** for validation\n",
    "* **624** for testing purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:39.387222Z",
     "iopub.status.busy": "2021-10-23T10:11:39.386962Z",
     "iopub.status.idle": "2021-10-23T10:11:42.222908Z",
     "shell.execute_reply": "2021-10-23T10:11:42.222055Z",
     "shell.execute_reply.started": "2021-10-23T10:11:39.387196Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plot three images of augmented training data\n",
    "for _ in range(3):\n",
    "    img, label = train_data.next()\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(img[0],cmap=\"gray\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:42.224499Z",
     "iopub.status.busy": "2021-10-23T10:11:42.224046Z",
     "iopub.status.idle": "2021-10-23T10:11:42.232696Z",
     "shell.execute_reply": "2021-10-23T10:11:42.231785Z",
     "shell.execute_reply.started": "2021-10-23T10:11:42.224464Z"
    },
    "id": "gl_M9hovYRYi"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_tensorboard_callback(dir_name, experiment_name):\n",
    "\n",
    "    #store log files with filepath to tensorboard\n",
    "    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=log_dir\n",
    "    )\n",
    "    print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
    "    return tensorboard_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnNAYaO3B6vC"
   },
   "source": [
    "**Create sequential deep learning model**\n",
    "\n",
    "* Get prediction probabilites later on using softmax activation function in dense layer\n",
    "* Use categorical crossentropy as loss metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:42.235704Z",
     "iopub.status.busy": "2021-10-23T10:11:42.235449Z",
     "iopub.status.idle": "2021-10-23T10:11:44.476955Z",
     "shell.execute_reply": "2021-10-23T10:11:44.476082Z",
     "shell.execute_reply.started": "2021-10-23T10:11:42.235671Z"
    },
    "id": "dgKMTEmrYUvT"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Activation,BatchNormalization, Dropout\n",
    "\n",
    "#Create model, increase filter and decrease kernel as going deeper since pixels are bigger than 128x128. This is the AlexNet neural netowrk\n",
    "#architecture\n",
    "\n",
    "model=Sequential([\n",
    "    Conv2D(96, 11, 4, activation='relu', input_shape=(224,224,1)),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(3, 2),\n",
    "    Conv2D(256, 5, 1, activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(3, 2),\n",
    "    Conv2D(384, 3, 1, activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(384,3, 1, activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    Conv2D(256, 3, 1, activation='relu', padding=\"same\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPool2D(3, 2),\n",
    "    Flatten(),\n",
    "    Dense(4096, activation='relu'),\n",
    "    \n",
    "    #set dropout to regularize\n",
    "    Dropout(0.5),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001,decay=1e-5),\n",
    "                metrics=[\"AUC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:44.478695Z",
     "iopub.status.busy": "2021-10-23T10:11:44.478340Z",
     "iopub.status.idle": "2021-10-23T10:11:44.487209Z",
     "shell.execute_reply": "2021-10-23T10:11:44.486432Z",
     "shell.execute_reply.started": "2021-10-23T10:11:44.478658Z"
    },
    "id": "-XhO3UnTYWDj"
   },
   "outputs": [],
   "source": [
    "# Set checkpoint path\n",
    "checkpoint_path = \"weights/checkpoint.ckpt\"\n",
    "\n",
    "# Create a ModelCheckpoint callback that saves the model's weights only\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                         save_best_only=True,\n",
    "                                                         save_freq=\"epoch\", # save every epoch\n",
    "                                                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-10-23T10:11:44.489992Z",
     "iopub.status.busy": "2021-10-23T10:11:44.489655Z",
     "iopub.status.idle": "2021-10-23T10:14:13.783791Z",
     "shell.execute_reply": "2021-10-23T10:14:13.781218Z",
     "shell.execute_reply.started": "2021-10-23T10:11:44.489960Z"
    },
    "id": "3Tu-3B5zYXKG",
    "outputId": "245e57df-247e-4835-b8f2-eb0c613be0bf"
   },
   "outputs": [],
   "source": [
    "# Fit the model saving checkpoints every epoch\n",
    "epochs = 50\n",
    "\n",
    "#Train the model with 150 epochs\n",
    "history = model.fit(train_data,\n",
    "                          epochs=epochs,\n",
    "                          steps_per_epoch=train_data.samples//BATCH_SIZE,\n",
    "                          validation_data=valid_data,\n",
    "                          validation_steps=len(valid_data),\n",
    "                          callbacks=[create_tensorboard_callback(dir_name=\"history_callback\",\n",
    "                                                                                 experiment_name=\"Chest_Xray\"),\n",
    "                                                     checkpoint_callback])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the model as it currently is versus the best fitted model during training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-23T10:14:13.785083Z",
     "iopub.status.idle": "2021-10-23T10:14:13.785808Z"
    },
    "id": "-oiMRWs-hUpK",
    "outputId": "30d3d49d-cb4c-4a52-fad8-5624fd178b7c"
   },
   "outputs": [],
   "source": [
    "model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-23T10:14:13.786974Z",
     "iopub.status.idle": "2021-10-23T10:14:13.787771Z"
    },
    "id": "-IykArdphbj0"
   },
   "outputs": [],
   "source": [
    "#Load best weights from the saved model on checkpoint\n",
    "model_best_weights= tf.keras.models.load_model('weights/checkpoint.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model with best weights achieved an accuracy of roughly 82%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-23T10:14:13.789014Z",
     "iopub.status.idle": "2021-10-23T10:14:13.789792Z"
    },
    "id": "oPbecGRVhk4v",
    "outputId": "c54bcb46-ba5d-4d6a-84fb-5bb7f4e3daf0"
   },
   "outputs": [],
   "source": [
    "model_best_weights.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and visualization\n",
    "\n",
    "* Predictions are made with the model fitted with best weights. Perhaps better result could be achieved by training longer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-23T10:14:13.791030Z",
     "iopub.status.idle": "2021-10-23T10:14:13.791931Z"
    },
    "id": "kkKArB0q4U-7",
    "outputId": "abfb5bb7-1cc5-4518-9bf4-78f7fd6294c2"
   },
   "outputs": [],
   "source": [
    "y_pred = model_best_weights.predict(test_data)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-23T10:14:13.793094Z",
     "iopub.status.idle": "2021-10-23T10:14:13.793879Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKPz2HX9B6vE"
   },
   "source": [
    "**Predict randomly and plot**\n",
    "\n",
    "This section takes 4 images out of testing data and classifies them using the model that was trained\n",
    "\n",
    "The actual and predicted categories plus their prediction probability is also plotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-23T10:14:13.795134Z",
     "iopub.status.idle": "2021-10-23T10:14:13.795940Z"
    },
    "id": "Fo5og2EJYK3D"
   },
   "outputs": [],
   "source": [
    "# Create a function to load and prepare images for prediction\n",
    "def load_and_prep_image(filename, img_shape=224, scale=True):\n",
    "\n",
    "  # Read in the image\n",
    "    img = tf.io.read_file(filename)\n",
    "\n",
    "    # Decode image into tensor\n",
    "    img = tf.io.decode_image(img, channels=1)\n",
    "\n",
    "    # Resize the image\n",
    "    img = tf.image.resize(img, [img_shape, img_shape])\n",
    "\n",
    "    # Scale? Yes/no\n",
    "    if scale:\n",
    "    # rescale the image (get all values between 0 and 1)\n",
    "        return img/255.\n",
    "    else:\n",
    "        return img "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-10-23T10:14:13.797124Z",
     "iopub.status.idle": "2021-10-23T10:14:13.797914Z"
    },
    "id": "YNYnRZUXYMMO",
    "outputId": "c1cbe9a9-6887-40c9-8c31-bc99764ef5f6"
   },
   "outputs": [],
   "source": [
    "# Make preds on a series of random images\n",
    "import os\n",
    "import random\n",
    "\n",
    "plt.figure(figsize=(17, 10))\n",
    "\n",
    "#get for random images from testdataset and use model to predict infection\n",
    "for i in range(4):\n",
    "    \n",
    "  # Choose random image(s) from random class(es)\n",
    "    class_name = random.choice(class_names)\n",
    "    filename = random.choice(os.listdir(test_dir + \"/\" + class_name))\n",
    "    filepath = test_dir + \"/\"+ class_name + \"/\" + filename\n",
    "\n",
    "    # Load the image and make predictions\n",
    "    img = load_and_prep_image(filepath)\n",
    "    \n",
    "    img_expanded = tf.expand_dims(img, axis=0)\n",
    "    print(img_expanded.shape)\n",
    "    pred_prob = model_best_weights.predict(img_expanded) # get prediction probabilities array\n",
    "    pred_class = class_names[pred_prob.argmax()] # get highest prediction probability index and match it class_names list\n",
    "    #slice out last dimension\n",
    "    img = img[:,:,0]\n",
    "    print(pred_prob)\n",
    "    plt.subplot(2, 2,i+1)\n",
    "    # Plot the images\n",
    "    print(filename)\n",
    "    plt.imshow(img,cmap='gray')\n",
    "    if (class_name == pred_class): # if predicted class matches truth class, make text green\n",
    "        title_color = \"g\"\n",
    "    else:\n",
    "        title_color = \"r\"\n",
    "    plt.title(f\"Actual class: {class_name}, Pred class: {pred_class}, Pred prob: {pred_prob.max():.2f}%\", c=title_color)\n",
    "    plt.axis(False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
